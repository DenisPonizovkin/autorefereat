
{\underline {\bf В первой главе}} введена терминология и обозначения РС,
дано определение модели РС и АКМ,
определены задачи и алгоритмы АКМ их решений во введенной терминологии.

Обозначим символом $X$ множество характеристик
пользователей, символом $Y$ --- множество характеристик объектов.
Значением характеристики пользователя
является значение весовой функции $w_U: U \times X \rightarrow[0,1]$,
объекта --- $w_I: I \times Y \rightarrow[0,1]$. Значения весов могут задаваться
пользователями, экспертами, алгоритмически и т.д. Структуру данных,
представляющую информацию о пользователе $u$ и объекте $i$ назовем
контентом пользователя $c_X(u)$ и контентом объекта $c_Y(i)$ соответственно.
Стандартно в исследованиях, посвященных коллаборативной фильтрации
контенты именуются профилями, $X = I$, $w_U(u, i) = \rho(u, i)$,
$Y = U$, $w_I(i, u) = 1$, если $u \R i$, 0 --- иначе. В описываемом
исследовании используется термин контент в более широком понимании
профиля, где множества характеристик могут быть не только $U$
или $I$.

Стоит отметить, что для АКМ $X = I$, $Y = U$,  $w_U(u, i) = w_I(u, i) = \rho(u,
i)$, а контент называется профилем. В описываемом исследовании мы используем
более широкую терминологию, чтобы потом применить ее для описания разработанной
модели, которая может быть применена не только тогда, когда
$X = I$, $Y = U$,  $w_U(u, i) = w_I(u, i) = \rho(u,i)$.

Модель РС --- это тройка:
\begin{equation}
	(c_X; c_Y; \Pi),
\end{equation} где
$\Pi$ --- правило алгоритмического вывода значения прогнозной функции $\rh$.
Модель задает способ представления контентов. Например, если используется
мера сходства косинус, то тогда контентом должен быть вектор.

Правила $\Pi$ АКМ основаны на коллаборативной фильтрации.
Коллаборативная фильтрация может производиться либо по множеству
пользователей,
и тогда будем называть модели, применяющие данный тип фильтрации,
субъектно-ориентированными (далее СОМ),
либо по множеству объектов,
и тогда будем называть модели, применяющие данный тип фильтрации,
объектно-ориентированными (ООМ)\footnote{Levinas C. A.
An Analysis of Memory Based Collaborative Filtering
Recommender Systems with Improvement Proposals: Master’s thesis: Universitat
Politècnica de Catalunya. 2014}. Как правило, СОМ используются для решения
задачи $pred$, ООМ --- для решения задачи $topN$. Поэтому
решение задачи $pred$ будем рассматривать в СОМ, $topN$ --- в ООМ.

Правило вывода СОМ (далее $\Pi_C$) основано на эвристическом утверждении, которое
гласит, что если в прошлом пользователи были близки по вкусам,
то и в будущем они будут близки по вкусам.
Во введенной терминологии данное утверждение примет следующий вид:
\begin{equation}
\label{srs-assert}
	\forall u_a, u: \text{если } (u_a \ru u) \text{ верное на } P_0
	\Rightarrow (u_a \ru u) \text{ верно на } P_{\bot}
\end{equation}
$\ru$ --- отношение близости пользователей.
Во время проведения тестов в качестве множества будущего времени
выступает тестовое множество.

Выполнение отношения близости $\ru$ между пользователями
устанавливается по значениям функций $\rhu: U \times U \rightarrow [0,1]$,
именуемых мерой близости, которые рассчитываются по контентам пользователей:
$\rhu(u, v)) \le \varepsilon_p \Leftrightarrow u \ru v$.
Характеристиками для
СОМ всегда выступают объекты, а значениями весов --- значения $\rho(u, i) \in
P_0$, которые были выставлены самими пользователями и
представляют предпочтения пользователей.
Пользователи, между которыми выполняется отношение близости, называются
соседями.

Правило $\Pi_C$ задается следующей формулой:
\begin{equation}
	\label{srs-pi}
	\forall u_a, u: (u_a \R u) \Leftrightarrow
	|\rh(u_a, i_{\bot}) - \rho(u_a, i_{\bot})|
	\le \varepsilon_p, \rh(u_a, i_{\bot}) := f(\{\rho(u, i_{\bot})\}).
\end{equation}
Правило $\Pi_C$ говорит о том, что если пользователи $u$ являются
соседями для пользователя $u_a$, то значения $\rho(u_a, i_{\bot})$ и $\rho(u, i_{\bot})$
коррелируют, поэтому неизвестное значение $\rh(u_a, i_{\bot})$ можно функционально определить по
значениям $\{\rho(u, i_{\bot})\}$, то есть прогнозная функция является функцией от
значений оценок близости соседей.

%Следствием вида характеристик
%является то, что СОМ
%может применяться для решения в том случае, если мощность
%множества $P_0$ достаточно велика (порог мощности варьируется от системе к
%системе и не установлен)
Стандартный алгоритм решения основан на фильтрации тех пользователей, которые не являются
соседями для активного пользователя: строится так называемый кластер
соседей фиксированного размера, центром которого является активный
пользователь $u_a$, а элементами --- соседи
$\mathcal{N}_U = \{ u : (u_a \ru u) \wedge
(u, i_{\bot}, \rho(u, i_{\bot})) \in P_0)$ \}.
Далее значение $\rh(u_a, i_{\bot})$ функционально вычисляется по оценкам
$\{\rho(u, i_{\bot})$, где $u \in \mathcal{N}_U\}$.
Например, функциональная связь может быть определена как
средняя оценка близости соседей:
$\overline{P}_{\bot} = \{ \rh(u_a, i_{\bot}) = \sum \limits_{u \in
\mathcal{N}_U} \rho(u, i_{\bot}) \} $

Правило вывода ООМ (далее $\Pi_O$) основано на эвристическом утверждении,
которое гласит, что если пользователю нравится объект $i$, который
похож на объект $j$, то пользователю понравится объект $j$. Данное
предположение используется при представлении множества $Y = U$ \footnote{},
так и в представлении множества $Y$ в виде множества некоторых характеристик,
например, кинематографических жанров \footnote{}.
Во введенной терминологии данное утверждение примет следующий вид:
\begin{equation}
\label{ors-assert}
(u_a \R i) \wedge (i \rt j) \Rightarrow u_a \R j
\end{equation}
$\rt$ --- отношение близости объектов.

Отношение близости $\rt$ между объектами
устанавливается на основании значений функций $\rho: I \times I \rightarrow [0,1]$,
именуемых мерой близости:
$\rhi(i, j) \le \varepsilon_i \Leftrightarrow i \rt j$,
Объекты, между которыми выполняется отношение близости, называются соседями.

При решении задачи $topN$ в ООМ используется
информация только о тех объектах, для которых известно, что $(u_a \R i_0)$,
а тестирование проводится с теми объектами, для которых известно, что
$(u_a \R i_{\bot})$, поэтому будем считать, что
$P = \{(i, \rho(u, i)): u \R i\}$ для задачи $topN$.
%То есть фильтруются
%те объекты, между которыми и объектами обучающего множества не выполняется
%отношение близости.

Правило $\Pi_O$ задается следующей формулой:
\begin{equation}
	\label{ors-pi}
	(i \rt i_0) \Rightarrow (\rh(u_a, i) := 0) \Rightarrow u_a \R i.
\end{equation}
Значения $\rh(u_a, i)$ задаются равными нулю, потому что тогда между
объектами $i$ и  активным пользователем будет выполняться отношение
близости при любых значениях
$\varepsilon_{\R}$.
Правило $\Pi_{OOM}$ говорит о том,
что если существует объект $i$, являющийся соседом для объекта $i_0$,
то, следуя эвристическому утверждению, выполняется отношение $u_a \R i$,
так как $u_a \R i_0$ по принятому для задачи $topN$ виду исходного множества.

Стандартно для решения задачи $topN$ строится кластер $I_{topN}$, центром
которого является множество $c := \{i: (u_a, i_0, \rho(u_a, i_0)) \in P_0\}$:
$I_{topN} = \{ i : c \rt i\}$, $c \rt i \Leftrightarrow \rhi^{\prime}(c, i) \le
\varepsilon_i$, где $\rhi^{\prime}(с, i)) = \underset{(u_a, i_0, \rho(u_a,
i_0)) \in c} {\mathrm{\max}}
\{ \rhi(i, i_0) \}$. Решением задачи $topN$ является $\overline{P}_{\bot} = \{ (i, \rh(u_a, i)) :
(\rh(u_a, i) = 0) \wedge (i \in I_{topN}) \wedge (i \not \in c)\}$.
